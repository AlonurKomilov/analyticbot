#!/usr/bin/env python3
"""
üß™ Phase 4.0 Advanced Analytics - Quick Test Suite

Simplified test to verify core functionality of all 5 modules.
"""

import asyncio
import sys
import os
import numpy as np
import pandas as pd
import logging
from datetime import datetime, timedelta

# Add the project root to Python path
sys.path.insert(0, '/workspaces/analyticbot')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_simple_test_data():
    """Create simple test dataset"""
    np.random.seed(42)
    
    df = pd.DataFrame({
        'timestamp': pd.date_range('2024-01-01', periods=100, freq='D'),
        'sales': 1000 + np.cumsum(np.random.normal(10, 50, 100)),
        'customers': np.random.poisson(50, 100),
        'region': np.random.choice(['North', 'South'], 100)
    })
    
    # Add some missing values
    df.loc[np.random.choice(df.index, 5), 'sales'] = np.nan
    
    return df

async def test_data_processor():
    """Test basic data processing functionality"""
    try:
        print("üß™ Testing Data Processor...")
        from bot.utils.data_processor import AdvancedDataProcessor
        
        processor = AdvancedDataProcessor()
        test_df = create_simple_test_data()
        
        # Test basic data quality analysis
        quality_report = await processor.analyze_data_quality(test_df)
        print(f"   ‚úÖ Data quality score: {quality_report['overall_score']:.1f}/100")
        
        # Test data cleaning
        cleaned_df = await processor.clean_data(test_df)
        print(f"   ‚úÖ Cleaned data: {cleaned_df.shape[0]} rows")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Data Processor test failed: {str(e)}")
        return False

async def test_predictive_engine():
    """Test basic predictive analytics"""
    try:
        print("üß™ Testing Predictive Engine...")
        from bot.services.ml.predictive_engine import PredictiveAnalyticsEngine
        
        engine = PredictiveAnalyticsEngine()
        test_df = create_simple_test_data().dropna()
        
        # Test simple ML prediction
        results = await engine.auto_predict(
            test_df, 
            'sales', 
            task_type='regression',
            test_size=0.3,
            optimize=False  # Disable optimization for speed
        )
        print(f"   ‚úÖ Best model: {results['best_model']}")
        print(f"   ‚úÖ Model score: {results['best_model_score']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Predictive Engine test failed: {str(e)}")
        return False

async def test_visualization():
    """Test visualization capabilities"""
    try:
        print("üß™ Testing Visualization Engine...")
        from bot.services.dashboard_service import VisualizationEngine
        
        viz_engine = VisualizationEngine()
        test_df = create_simple_test_data().dropna()
        
        # Test basic chart creation
        line_chart = viz_engine.create_line_chart(
            test_df.head(50),
            'timestamp',
            'sales',
            title="Test Sales Chart"
        )
        print(f"   ‚úÖ Line chart created")
        
        # Test bar chart
        bar_data = test_df.groupby('region')['sales'].sum().reset_index()
        bar_chart = viz_engine.create_bar_chart(
            bar_data,
            'region',
            'sales',
            title="Sales by Region"
        )
        print(f"   ‚úÖ Bar chart created")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Visualization test failed: {str(e)}")
        return False

async def test_ai_insights():
    """Test AI insights generation"""
    try:
        print("üß™ Testing AI Insights Generator...")
        from bot.services.ml.ai_insights import AIInsightsGenerator
        
        insights_gen = AIInsightsGenerator()
        test_df = create_simple_test_data()
        
        # Test basic insights generation
        insights = await insights_gen.generate_comprehensive_insights(
            test_df,
            target_column='sales',
            time_column='timestamp',
            insight_types=['statistical_summary', 'correlation_insights']  # Limited for speed
        )
        print(f"   ‚úÖ Insights generated: {len(insights['insights'])} types")
        print(f"   ‚úÖ Recommendations: {len(insights['recommendations'])}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå AI Insights test failed: {str(e)}")
        return False

async def test_reporting():
    """Test reporting system"""
    try:
        print("üß™ Testing Reporting System...")
        from bot.services.reporting_service import AutomatedReportingSystem
        
        reporting_system = AutomatedReportingSystem(output_directory="/tmp/quick_test_reports")
        test_df = create_simple_test_data()
        
        # Create simple template
        template = reporting_system.create_template(
            template_name='quick_test',
            sections=['executive_summary', 'key_metrics']
        )
        print(f"   ‚úÖ Template created: {template.name}")
        
        # Generate simple report
        output_files = await reporting_system.generate_comprehensive_report(
            data_source=test_df,
            template_name='quick_test',
            report_title='Quick Test Report',
            output_formats=['json'],  # Just JSON for speed
            include_insights=False,
            include_predictions=False
        )
        print(f"   ‚úÖ Report generated: {len(output_files)} formats")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Reporting test failed: {str(e)}")
        return False

async def main():
    """Run quick test suite"""
    print("üöÄ PHASE 4.0 ADVANCED ANALYTICS - QUICK TEST SUITE")
    print("=" * 60)
    print(f"‚è∞ Test started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Run tests
    test_results = []
    
    test_results.append(('Data Processor', await test_data_processor()))
    test_results.append(('Predictive Engine', await test_predictive_engine()))
    test_results.append(('Visualization', await test_visualization()))
    test_results.append(('AI Insights', await test_ai_insights()))
    test_results.append(('Reporting System', await test_reporting()))
    
    # Print results
    print("\n" + "=" * 60)
    print("üìä QUICK TEST RESULTS")
    print("=" * 60)
    
    passed_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results:
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{test_name:<20} {status}")
        if result:
            passed_tests += 1
    
    print("-" * 60)
    print(f"SUCCESS RATE: {(passed_tests/total_tests)*100:.1f}% ({passed_tests}/{total_tests})")
    
    if passed_tests == total_tests:
        print("\nüéâ ALL TESTS PASSED! üéâ")
        print("\nüìã PHASE 4.0 MODULES VERIFIED:")
        print("‚úÖ Module 4.1: Advanced Data Processing Engine")
        print("‚úÖ Module 4.2: Predictive Analytics & Forecasting")
        print("‚úÖ Module 4.3: Real-time Analytics Dashboard")
        print("‚úÖ Module 4.4: AI-Powered Insights Generator")
        print("‚úÖ Module 4.5: Automated Reporting System")
        print("\nüöÄ ENTERPRISE DATA SCIENCE PLATFORM READY!")
    else:
        print(f"\n‚ö†Ô∏è  {total_tests - passed_tests} TEST(S) FAILED")
    
    print(f"\n‚è∞ Test completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    asyncio.run(main())
