"""
AI Insights Fusion Package
===========================

Microservices package for AI insights functionality.

Transformed from: AIInsightsService (803 lines) god object
Into: 5 focused microservices with single responsibilities

Package Structure:
- protocols/: Protocol interfaces for dependency injection
- insights/: Core insights generation service
- patterns/: Pattern analysis service
- predictions/: Predictive analysis service
- integration/: Service integration service
- orchestrator/: Main orchestrator service

Factory Function: create_ai_insights_orchestrator() - Easy instantiation
"""

import logging

from .insights.core_insights_service import CoreInsightsService
from .integration.service_integration_service import ServiceIntegrationService
from .orchestrator.ai_insights_orchestrator_service import AIInsightsOrchestratorService
from .patterns.pattern_analysis_service import PatternAnalysisService
from .predictions.predictive_analysis_service import PredictiveAnalysisService
from .protocols.ai_insights_protocols import (
    AIInsightsOrchestratorProtocol,
    CoreInsightsProtocol,
    PatternAnalysisProtocol,
    PredictiveAnalysisProtocol,
    ServiceIntegrationProtocol,
)

logger = logging.getLogger(__name__)

__all__ = [
    # Protocols
    "CoreInsightsProtocol",
    "PatternAnalysisProtocol",
    "PredictiveAnalysisProtocol",
    "ServiceIntegrationProtocol",
    "AIInsightsOrchestratorProtocol",
    # Services
    "CoreInsightsService",
    "PatternAnalysisService",
    "PredictiveAnalysisService",
    "ServiceIntegrationService",
    "AIInsightsOrchestratorService",
    # Factory
    "create_ai_insights_orchestrator",
]


def create_ai_insights_orchestrator(
    data_access_service=None,
    analytics_models_service=None,
    config_manager=None,
    nlg_integration_service=None,
    ai_chat_service=None,
    anomaly_analysis_service=None,
    logger_instance=None,
) -> AIInsightsOrchestratorService:
    """
    Factory function to create fully configured AI insights orchestrator.

    Creates all microservices with proper dependency injection.

    Args:
        data_access_service: Data access service for analytics data
        analytics_models_service: Analytics models service for ML operations
        config_manager: Configuration management service
        nlg_integration_service: Existing NLG integration service
        ai_chat_service: Existing AI chat service
        anomaly_analysis_service: Existing anomaly analysis service
        logger_instance: Optional logger instance

    Returns:
        AIInsightsOrchestratorService: Fully configured orchestrator

    Example:
        ```python
        # Create orchestrator with dependencies
        orchestrator = create_ai_insights_orchestrator(
            data_access_service=data_access,
            analytics_models_service=models,
            config_manager=config,
            nlg_integration_service=nlg_service,
            ai_chat_service=chat_service,
            anomaly_analysis_service=anomaly_service
        )

        # Use orchestrator
        insights = await orchestrator.orchestrate_comprehensive_insights(
            channel_id=123,
            narrative_style="executive",
            days_analyzed=30
        )
        ```
    """
    try:
        if logger_instance:
            logger.setLevel(logger_instance.level)

        logger.info("üè≠ Creating AI Insights Orchestrator with microservices")

        # Create core insights service
        # Note: Expects repository parameters, not service parameters
        core_insights_service = CoreInsightsService(
            channel_daily_repo=None,  # Will be injected via DI in apps layer
            post_repo=None,
            metrics_repo=None,
        )
        logger.info("‚úÖ Core insights service created")

        # Create pattern analysis service
        pattern_analysis_service = PatternAnalysisService()
        logger.info("‚úÖ Pattern analysis service created")

        # Create predictive analysis service
        predictive_analysis_service = PredictiveAnalysisService()
        logger.info("‚úÖ Predictive analysis service created")

        # Create service integration service (with existing AI services)
        service_integration_service = ServiceIntegrationService(
            nlg_integration_service=nlg_integration_service,
            ai_chat_service=ai_chat_service,
            anomaly_analysis_service=anomaly_analysis_service,
        )
        logger.info("‚úÖ Service integration service created")

        # Create main orchestrator
        orchestrator = AIInsightsOrchestratorService(
            core_insights_service=core_insights_service,
            pattern_analysis_service=pattern_analysis_service,
            predictive_analysis_service=predictive_analysis_service,
            service_integration_service=service_integration_service,
        )
        logger.info("‚úÖ AI insights orchestrator created")

        logger.info("üéâ AI Insights Fusion package initialized successfully")
        logger.info(
            "üìä Microservices created: 5 (Core, Patterns, Predictions, Integration, Orchestrator)"
        )

        return orchestrator

    except Exception as e:
        logger.error(f"‚ùå Failed to create AI insights orchestrator: {e}")
        raise


# Package metadata
__version__ = "1.0.0"
__description__ = "AI Insights Fusion - Microservices package for AI insights generation"
__transformation_source__ = "AIInsightsService (803 lines)"
__microservices_count__ = 5
__architecture__ = "protocol_based_dependency_injection"

# Transformation summary
TRANSFORMATION_SUMMARY = {
    "source_god_object": "AIInsightsService",
    "source_lines": 803,
    "microservices_created": 5,
    "architecture_pattern": "protocol_based_dependency_injection",
    "single_responsibility_principle": True,
    "dependency_injection": "protocol_based",
    "factory_pattern": True,
    "microservices": {
        "CoreInsightsService": {
            "responsibility": "core_insights_generation",
            "protocol": "CoreInsightsProtocol",
            "estimated_lines": 300,
        },
        "PatternAnalysisService": {
            "responsibility": "pattern_analysis",
            "protocol": "PatternAnalysisProtocol",
            "estimated_lines": 400,
        },
        "PredictiveAnalysisService": {
            "responsibility": "predictive_analysis",
            "protocol": "PredictiveAnalysisProtocol",
            "estimated_lines": 300,
        },
        "ServiceIntegrationService": {
            "responsibility": "service_integration",
            "protocol": "ServiceIntegrationProtocol",
            "estimated_lines": 250,
        },
        "AIInsightsOrchestratorService": {
            "responsibility": "workflow_orchestration",
            "protocol": "AIInsightsOrchestratorProtocol",
            "estimated_lines": 400,
        },
    },
    "total_microservices_lines": 1650,
    "code_expansion_factor": 2.05,
    "benefits": [
        "single_responsibility_principle",
        "protocol_based_dependency_injection",
        "easy_testing_and_mocking",
        "independent_deployment",
        "clear_separation_of_concerns",
        "factory_pattern_for_easy_instantiation",
    ],
}
